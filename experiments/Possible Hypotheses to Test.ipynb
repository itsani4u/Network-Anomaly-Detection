{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ab30a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bfd8217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee8525da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration protocoltype   service flag  srcbytes  dstbytes  land  \\\n",
      "0         0          tcp  ftp_data   SF       491         0     0   \n",
      "1         0          udp     other   SF       146         0     0   \n",
      "2         0          tcp   private   S0         0         0     0   \n",
      "3         0          tcp      http   SF       232      8153     0   \n",
      "4         0          tcp      http   SF       199       420     0   \n",
      "\n",
      "   wrongfragment  urgent  hot  ...  dsthostsamesrvrate  dsthostdiffsrvrate  \\\n",
      "0              0       0    0  ...                0.17                0.03   \n",
      "1              0       0    0  ...                0.00                0.60   \n",
      "2              0       0    0  ...                0.10                0.05   \n",
      "3              0       0    0  ...                1.00                0.00   \n",
      "4              0       0    0  ...                1.00                0.00   \n",
      "\n",
      "   dsthostsamesrcportrate  dsthostsrvdiffhostrate  dsthostserrorrate  \\\n",
      "0                    0.17                    0.00               0.00   \n",
      "1                    0.88                    0.00               0.00   \n",
      "2                    0.00                    0.00               1.00   \n",
      "3                    0.03                    0.04               0.03   \n",
      "4                    0.00                    0.00               0.00   \n",
      "\n",
      "   dsthostsrvserrorrate  dsthostrerrorrate  dsthostsrvrerrorrate   attack  \\\n",
      "0                  0.00               0.05                  0.00   normal   \n",
      "1                  0.00               0.00                  0.00   normal   \n",
      "2                  1.00               0.00                  0.00  neptune   \n",
      "3                  0.01               0.00                  0.01   normal   \n",
      "4                  0.00               0.00                  0.00   normal   \n",
      "\n",
      "   lastflag  \n",
      "0        20  \n",
      "1        15  \n",
      "2        19  \n",
      "3        21  \n",
      "4        21  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 43 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   duration                125973 non-null  int64  \n",
      " 1   protocoltype            125973 non-null  object \n",
      " 2   service                 125973 non-null  object \n",
      " 3   flag                    125973 non-null  object \n",
      " 4   srcbytes                125973 non-null  int64  \n",
      " 5   dstbytes                125973 non-null  int64  \n",
      " 6   land                    125973 non-null  int64  \n",
      " 7   wrongfragment           125973 non-null  int64  \n",
      " 8   urgent                  125973 non-null  int64  \n",
      " 9   hot                     125973 non-null  int64  \n",
      " 10  numfailedlogins         125973 non-null  int64  \n",
      " 11  loggedin                125973 non-null  int64  \n",
      " 12  numcompromised          125973 non-null  int64  \n",
      " 13  rootshell               125973 non-null  int64  \n",
      " 14  suattempted             125973 non-null  int64  \n",
      " 15  numroot                 125973 non-null  int64  \n",
      " 16  numfilecreations        125973 non-null  int64  \n",
      " 17  numshells               125973 non-null  int64  \n",
      " 18  numaccessfiles          125973 non-null  int64  \n",
      " 19  numoutboundcmds         125973 non-null  int64  \n",
      " 20  ishostlogin             125973 non-null  int64  \n",
      " 21  isguestlogin            125973 non-null  int64  \n",
      " 22  count                   125973 non-null  int64  \n",
      " 23  srvcount                125973 non-null  int64  \n",
      " 24  serrorrate              125973 non-null  float64\n",
      " 25  srvserrorrate           125973 non-null  float64\n",
      " 26  rerrorrate              125973 non-null  float64\n",
      " 27  srvrerrorrate           125973 non-null  float64\n",
      " 28  samesrvrate             125973 non-null  float64\n",
      " 29  diffsrvrate             125973 non-null  float64\n",
      " 30  srvdiffhostrate         125973 non-null  float64\n",
      " 31  dsthostcount            125973 non-null  int64  \n",
      " 32  dsthostsrvcount         125973 non-null  int64  \n",
      " 33  dsthostsamesrvrate      125973 non-null  float64\n",
      " 34  dsthostdiffsrvrate      125973 non-null  float64\n",
      " 35  dsthostsamesrcportrate  125973 non-null  float64\n",
      " 36  dsthostsrvdiffhostrate  125973 non-null  float64\n",
      " 37  dsthostserrorrate       125973 non-null  float64\n",
      " 38  dsthostsrvserrorrate    125973 non-null  float64\n",
      " 39  dsthostrerrorrate       125973 non-null  float64\n",
      " 40  dsthostsrvrerrorrate    125973 non-null  float64\n",
      " 41  attack                  125973 non-null  object \n",
      " 42  lastflag                125973 non-null  int64  \n",
      "dtypes: float64(15), int64(24), object(4)\n",
      "memory usage: 41.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"Network_anomaly_data.csv\")\n",
    "\n",
    "# Check the first few rows of the data\n",
    "print(df.head())\n",
    "\n",
    "# Get general information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d51b3a08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "duration                  0\n",
      "protocoltype              0\n",
      "service                   0\n",
      "flag                      0\n",
      "srcbytes                  0\n",
      "dstbytes                  0\n",
      "land                      0\n",
      "wrongfragment             0\n",
      "urgent                    0\n",
      "hot                       0\n",
      "numfailedlogins           0\n",
      "loggedin                  0\n",
      "numcompromised            0\n",
      "rootshell                 0\n",
      "suattempted               0\n",
      "numroot                   0\n",
      "numfilecreations          0\n",
      "numshells                 0\n",
      "numaccessfiles            0\n",
      "numoutboundcmds           0\n",
      "ishostlogin               0\n",
      "isguestlogin              0\n",
      "count                     0\n",
      "srvcount                  0\n",
      "serrorrate                0\n",
      "srvserrorrate             0\n",
      "rerrorrate                0\n",
      "srvrerrorrate             0\n",
      "samesrvrate               0\n",
      "diffsrvrate               0\n",
      "srvdiffhostrate           0\n",
      "dsthostcount              0\n",
      "dsthostsrvcount           0\n",
      "dsthostsamesrvrate        0\n",
      "dsthostdiffsrvrate        0\n",
      "dsthostsamesrcportrate    0\n",
      "dsthostsrvdiffhostrate    0\n",
      "dsthostserrorrate         0\n",
      "dsthostsrvserrorrate      0\n",
      "dsthostrerrorrate         0\n",
      "dsthostsrvrerrorrate      0\n",
      "attack                    0\n",
      "lastflag                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display missing values before handling\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "914c9d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Replace missing values in numerical columns with the median\n",
    "for col in numerical_columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Replace missing values in categorical columns with the most frequent value\n",
    "for col in categorical_columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a7b5af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after handling:\n",
      "duration                  0\n",
      "protocoltype              0\n",
      "service                   0\n",
      "flag                      0\n",
      "srcbytes                  0\n",
      "dstbytes                  0\n",
      "land                      0\n",
      "wrongfragment             0\n",
      "urgent                    0\n",
      "hot                       0\n",
      "numfailedlogins           0\n",
      "loggedin                  0\n",
      "numcompromised            0\n",
      "rootshell                 0\n",
      "suattempted               0\n",
      "numroot                   0\n",
      "numfilecreations          0\n",
      "numshells                 0\n",
      "numaccessfiles            0\n",
      "numoutboundcmds           0\n",
      "ishostlogin               0\n",
      "isguestlogin              0\n",
      "count                     0\n",
      "srvcount                  0\n",
      "serrorrate                0\n",
      "srvserrorrate             0\n",
      "rerrorrate                0\n",
      "srvrerrorrate             0\n",
      "samesrvrate               0\n",
      "diffsrvrate               0\n",
      "srvdiffhostrate           0\n",
      "dsthostcount              0\n",
      "dsthostsrvcount           0\n",
      "dsthostsamesrvrate        0\n",
      "dsthostdiffsrvrate        0\n",
      "dsthostsamesrcportrate    0\n",
      "dsthostsrvdiffhostrate    0\n",
      "dsthostserrorrate         0\n",
      "dsthostsrvserrorrate      0\n",
      "dsthostrerrorrate         0\n",
      "dsthostsrvrerrorrate      0\n",
      "attack                    0\n",
      "lastflag                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display missing values after handling\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04a3659f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before removal: 0\n",
      "Number of duplicates after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Number of duplicates before removal: {df.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Verify if duplicates are removed\n",
    "print(f\"Number of duplicates after removal: {df_cleaned.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bdc5b60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Dataset:\n",
      "   duration  protocoltype  service  flag  srcbytes  dstbytes  land  \\\n",
      "0         0             1       20     9       491         0     0   \n",
      "1         0             2       44     9       146         0     0   \n",
      "2         0             1       49     5         0         0     0   \n",
      "3         0             1       24     9       232      8153     0   \n",
      "4         0             1       24     9       199       420     0   \n",
      "\n",
      "   wrongfragment  urgent  hot  ...  dsthostsamesrvrate  dsthostdiffsrvrate  \\\n",
      "0              0       0    0  ...                0.17                0.03   \n",
      "1              0       0    0  ...                0.00                0.60   \n",
      "2              0       0    0  ...                0.10                0.05   \n",
      "3              0       0    0  ...                1.00                0.00   \n",
      "4              0       0    0  ...                1.00                0.00   \n",
      "\n",
      "   dsthostsamesrcportrate  dsthostsrvdiffhostrate  dsthostserrorrate  \\\n",
      "0                    0.17                    0.00               0.00   \n",
      "1                    0.88                    0.00               0.00   \n",
      "2                    0.00                    0.00               1.00   \n",
      "3                    0.03                    0.04               0.03   \n",
      "4                    0.00                    0.00               0.00   \n",
      "\n",
      "   dsthostsrvserrorrate  dsthostrerrorrate  dsthostsrvrerrorrate   attack  \\\n",
      "0                  0.00               0.05                  0.00   normal   \n",
      "1                  0.00               0.00                  0.00   normal   \n",
      "2                  1.00               0.00                  0.00  neptune   \n",
      "3                  0.01               0.00                  0.01   normal   \n",
      "4                  0.00               0.00                  0.00   normal   \n",
      "\n",
      "   lastflag  \n",
      "0        20  \n",
      "1        15  \n",
      "2        19  \n",
      "3        21  \n",
      "4        21  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['protocoltype', 'service', 'flag']\n",
    "\n",
    "# Dictionary to store mappings\n",
    "label_encoders = {}\n",
    "label_mappings = {}\n",
    "\n",
    "# Apply Label Encoding and store mappings\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    label_mappings[col] = {index: label for index, label in enumerate(le.classes_)}\n",
    "\n",
    "# Print the mappings for each column\n",
    "'''\n",
    "for col, mapping in label_mappings.items():\n",
    "    print(f\"Mapping for {col}:\")\n",
    "    for encoded, original in mapping.items():\n",
    "        print(f\"  {encoded} -> {original}\")\n",
    "    print()\n",
    "'''\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nEncoded Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21e1f7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Dataset (first 5 rows):\n",
      "   duration  protocoltype   service      flag  srcbytes  dstbytes      land  \\\n",
      "0 -0.110249     -0.124706 -0.686785  0.751111 -0.007679 -0.004919 -0.014089   \n",
      "1 -0.110249      2.219312  0.781428  0.751111 -0.007737 -0.004919 -0.014089   \n",
      "2 -0.110249     -0.124706  1.087305 -0.736235 -0.007762 -0.004919 -0.014089   \n",
      "3 -0.110249     -0.124706 -0.442083  0.751111 -0.007723 -0.002891 -0.014089   \n",
      "4 -0.110249     -0.124706 -0.442083  0.751111 -0.007728 -0.004814 -0.014089   \n",
      "\n",
      "   wrongfragment    urgent       hot  ...  dsthostsamesrvrate  \\\n",
      "0      -0.089486 -0.007736 -0.095076  ...           -0.782367   \n",
      "1      -0.089486 -0.007736 -0.095076  ...           -1.161030   \n",
      "2      -0.089486 -0.007736 -0.095076  ...           -0.938287   \n",
      "3      -0.089486 -0.007736 -0.095076  ...            1.066401   \n",
      "4      -0.089486 -0.007736 -0.095076  ...            1.066401   \n",
      "\n",
      "   dsthostdiffsrvrate  dsthostsamesrcportrate  dsthostsrvdiffhostrate  \\\n",
      "0           -0.280282                0.069972               -0.289103   \n",
      "1            2.736852                2.367737               -0.289103   \n",
      "2           -0.174417               -0.480197               -0.289103   \n",
      "3           -0.439078               -0.383108                0.066252   \n",
      "4           -0.439078               -0.480197               -0.289103   \n",
      "\n",
      "   dsthostserrorrate  dsthostsrvserrorrate  dsthostrerrorrate  \\\n",
      "0          -0.639532             -0.624871          -0.224532   \n",
      "1          -0.639532             -0.624871          -0.387635   \n",
      "2           1.608759              1.618955          -0.387635   \n",
      "3          -0.572083             -0.602433          -0.387635   \n",
      "4          -0.639532             -0.624871          -0.387635   \n",
      "\n",
      "   dsthostsrvrerrorrate   attack  lastflag  \n",
      "0             -0.376387   normal  0.216426  \n",
      "1             -0.376387   normal -1.965556  \n",
      "2             -0.376387  neptune -0.219970  \n",
      "3             -0.345084   normal  0.652823  \n",
      "4             -0.376387   normal  0.652823  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Normalized Dataset (first 5 rows):\n",
      "   duration  protocoltype   service  flag      srcbytes      dstbytes  land  \\\n",
      "0       0.0           0.5  0.289855   0.9  3.558064e-07  0.000000e+00   0.0   \n",
      "1       0.0           1.0  0.637681   0.9  1.057999e-07  0.000000e+00   0.0   \n",
      "2       0.0           0.5  0.710145   0.5  0.000000e+00  0.000000e+00   0.0   \n",
      "3       0.0           0.5  0.347826   0.9  1.681203e-07  6.223962e-06   0.0   \n",
      "4       0.0           0.5  0.347826   0.9  1.442067e-07  3.206260e-07   0.0   \n",
      "\n",
      "   wrongfragment  urgent  hot  ...  dsthostsamesrvrate  dsthostdiffsrvrate  \\\n",
      "0            0.0     0.0  0.0  ...                0.17                0.03   \n",
      "1            0.0     0.0  0.0  ...                0.00                0.60   \n",
      "2            0.0     0.0  0.0  ...                0.10                0.05   \n",
      "3            0.0     0.0  0.0  ...                1.00                0.00   \n",
      "4            0.0     0.0  0.0  ...                1.00                0.00   \n",
      "\n",
      "   dsthostsamesrcportrate  dsthostsrvdiffhostrate  dsthostserrorrate  \\\n",
      "0                    0.17                    0.00               0.00   \n",
      "1                    0.88                    0.00               0.00   \n",
      "2                    0.00                    0.00               1.00   \n",
      "3                    0.03                    0.04               0.03   \n",
      "4                    0.00                    0.00               0.00   \n",
      "\n",
      "   dsthostsrvserrorrate  dsthostrerrorrate  dsthostsrvrerrorrate   attack  \\\n",
      "0                  0.00               0.05                  0.00   normal   \n",
      "1                  0.00               0.00                  0.00   normal   \n",
      "2                  1.00               0.00                  0.00  neptune   \n",
      "3                  0.01               0.00                  0.01   normal   \n",
      "4                  0.00               0.00                  0.00   normal   \n",
      "\n",
      "   lastflag  \n",
      "0  0.952381  \n",
      "1  0.714286  \n",
      "2  0.904762  \n",
      "3  1.000000  \n",
      "4  1.000000  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns to scale/normalize\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Standardization: Mean = 0, Std Dev = 1\n",
    "standard_scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[numerical_columns] = standard_scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Normalization: Scale to range [0, 1]\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_normalized = df.copy()\n",
    "df_normalized[numerical_columns] = minmax_scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Display the transformed datasets\n",
    "print(\"Standardized Dataset (first 5 rows):\")\n",
    "print(df_standardized.head())\n",
    "\n",
    "print(\"\\nNormalized Dataset (first 5 rows):\")\n",
    "print(df_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "857e2304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated column pairs (correlation > 0.9):\n",
      "numroot and numcompromised\n",
      "srvserrorrate and serrorrate\n",
      "srvrerrorrate and rerrorrate\n",
      "dsthostserrorrate and serrorrate\n",
      "dsthostserrorrate and srvserrorrate\n",
      "dsthostsrvserrorrate and serrorrate\n",
      "dsthostsrvserrorrate and srvserrorrate\n",
      "dsthostsrvserrorrate and dsthostserrorrate\n",
      "dsthostrerrorrate and rerrorrate\n",
      "dsthostrerrorrate and srvrerrorrate\n",
      "dsthostsrvrerrorrate and rerrorrate\n",
      "dsthostsrvrerrorrate and srvrerrorrate\n",
      "dsthostsrvrerrorrate and dsthostrerrorrate\n",
      "\n",
      "Dropped features due to high correlation: {'srvrerrorrate', 'numroot', 'dsthostsrvserrorrate', 'dsthostserrorrate', 'dsthostrerrorrate', 'srvserrorrate', 'dsthostsrvrerrorrate'}\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric fields\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Set a threshold for correlation (e.g., 0.9)\n",
    "threshold = 0.9\n",
    "\n",
    "# Initialize a list to store correlated column pairs\n",
    "correlated_pairs = []\n",
    "\n",
    "# Find highly correlated features\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:  # Check if correlation is above the threshold\n",
    "            colname1 = correlation_matrix.columns[i]\n",
    "            colname2 = correlation_matrix.columns[j]\n",
    "            correlated_pairs.append((colname1, colname2))\n",
    "\n",
    "# Print correlated column pairs\n",
    "if correlated_pairs:\n",
    "    print(\"Highly correlated column pairs (correlation > 0.9):\")\n",
    "    for pair in correlated_pairs:\n",
    "        print(f\"{pair[0]} and {pair[1]}\")\n",
    "else:\n",
    "    print(\"No highly correlated column pairs found.\")\n",
    "\n",
    "# Initialize a set to keep track of features to drop\n",
    "correlated_features = set()\n",
    "\n",
    "# Keep only the first feature of each correlated pair (drop the second one)\n",
    "for pair in correlated_pairs:\n",
    "    correlated_features.add(pair[0])  # Add only the first feature to the drop list\n",
    "\n",
    "# Drop the selected features from the original dataframe\n",
    "df = df.drop(columns=correlated_features)\n",
    "\n",
    "# Output the dropped features\n",
    "print(f\"\\nDropped features due to high correlation: {correlated_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49e972c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocoltype</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>srcbytes</th>\n",
       "      <th>dstbytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrongfragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>diffsrvrate</th>\n",
       "      <th>srvdiffhostrate</th>\n",
       "      <th>dsthostcount</th>\n",
       "      <th>dsthostsrvcount</th>\n",
       "      <th>dsthostsamesrvrate</th>\n",
       "      <th>dsthostdiffsrvrate</th>\n",
       "      <th>dsthostsamesrcportrate</th>\n",
       "      <th>dsthostsrvdiffhostrate</th>\n",
       "      <th>attack</th>\n",
       "      <th>lastflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocoltype  service  flag  srcbytes  dstbytes  land  \\\n",
       "0         0             1       20     9       491         0     0   \n",
       "1         0             2       44     9       146         0     0   \n",
       "2         0             1       49     5         0         0     0   \n",
       "3         0             1       24     9       232      8153     0   \n",
       "4         0             1       24     9       199       420     0   \n",
       "\n",
       "   wrongfragment  urgent  hot  ...  diffsrvrate  srvdiffhostrate  \\\n",
       "0              0       0    0  ...         0.00             0.00   \n",
       "1              0       0    0  ...         0.15             0.00   \n",
       "2              0       0    0  ...         0.07             0.00   \n",
       "3              0       0    0  ...         0.00             0.00   \n",
       "4              0       0    0  ...         0.00             0.09   \n",
       "\n",
       "   dsthostcount  dsthostsrvcount  dsthostsamesrvrate  dsthostdiffsrvrate  \\\n",
       "0           150               25                0.17                0.03   \n",
       "1           255                1                0.00                0.60   \n",
       "2           255               26                0.10                0.05   \n",
       "3            30              255                1.00                0.00   \n",
       "4           255              255                1.00                0.00   \n",
       "\n",
       "   dsthostsamesrcportrate  dsthostsrvdiffhostrate   attack  lastflag  \n",
       "0                    0.17                    0.00   normal        20  \n",
       "1                    0.88                    0.00   normal        15  \n",
       "2                    0.00                    0.00  neptune        19  \n",
       "3                    0.03                    0.04   normal        21  \n",
       "4                    0.00                    0.00   normal        21  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fefe23-6358-4f95-bc9b-54a236cb0058",
   "metadata": {},
   "source": [
    "# 1. Network Traffic Volume and Anomalies:\n",
    "\n",
    "Hypothesis: Network connections with unusually high or low traffic volume (bytes transferred) are more likely to be anomalous.\n",
    "\n",
    "Tests: Use t-tests or ANOVA to compare the means of Src_bytes and Dst_bytes in normal versus anomalous connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67d6c460-def6-4172-b7e9-7f4f88d81532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis for Src_bytes:\n",
      "Null Hypothesis (H0): The mean Src_bytes is the same for Normal and Anomalous connections.\n",
      "Alternative Hypothesis (Ha): The mean Src_bytes is different for Normal and Anomalous connections.\n",
      "T-statistic: -1.96, p-value: 0.0498\n",
      "Conclusion: Reject the null hypothesis. Significant difference in Src_bytes means between Normal and Anomalous connections.\n",
      "\n",
      "Hypothesis for Dst_bytes:\n",
      "Null Hypothesis (H0): The mean Dst_bytes is the same for Normal and Anomalous connections.\n",
      "Alternative Hypothesis (Ha): The mean Dst_bytes is different for Normal and Anomalous connections.\n",
      "T-statistic: -1.36, p-value: 0.1727\n",
      "Conclusion: Fail to reject the null hypothesis. No significant difference in Dst_bytes means.\n"
     ]
    }
   ],
   "source": [
    "# Define Normal and Anomalous categories\n",
    "normal_connections = df[df[\"attack\"] == \"normal\"]\n",
    "anomalous_connections = df[df[\"attack\"] != \"normal\"]\n",
    "\n",
    "# Perform t-tests for Src_bytes and Dst_bytes\n",
    "ttest_src = ttest_ind(normal_connections[\"srcbytes\"], anomalous_connections[\"srcbytes\"], equal_var=False)\n",
    "ttest_dst = ttest_ind(normal_connections[\"dstbytes\"], anomalous_connections[\"dstbytes\"], equal_var=False)\n",
    "\n",
    "# Print the hypotheses and results\n",
    "print(\"Hypothesis for Src_bytes:\")\n",
    "print(\"Null Hypothesis (H0): The mean Src_bytes is the same for Normal and Anomalous connections.\")\n",
    "print(\"Alternative Hypothesis (Ha): The mean Src_bytes is different for Normal and Anomalous connections.\")\n",
    "print(f\"T-statistic: {ttest_src.statistic:.2f}, p-value: {ttest_src.pvalue:.4f}\")\n",
    "if ttest_src.pvalue < 0.05:\n",
    "    print(\"Conclusion: Reject the null hypothesis. Significant difference in Src_bytes means between Normal and Anomalous connections.\\n\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference in Src_bytes means.\\n\")\n",
    "\n",
    "print(\"Hypothesis for Dst_bytes:\")\n",
    "print(\"Null Hypothesis (H0): The mean Dst_bytes is the same for Normal and Anomalous connections.\")\n",
    "print(\"Alternative Hypothesis (Ha): The mean Dst_bytes is different for Normal and Anomalous connections.\")\n",
    "print(f\"T-statistic: {ttest_dst.statistic:.2f}, p-value: {ttest_dst.pvalue:.4f}\")\n",
    "if ttest_dst.pvalue < 0.05:\n",
    "    print(\"Conclusion: Reject the null hypothesis. Significant difference in Dst_bytes means between Normal and Anomalous connections.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference in Dst_bytes means.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d962d-a368-4f2d-81cd-87d31373757e",
   "metadata": {},
   "source": [
    "# 2. Impact of Protocol Type on Anomaly Detection:\n",
    "\n",
    "Hypothesis: Certain protocols are more frequently associated with network anomalies.\n",
    "\n",
    "Tests: Chi-square test to determine if the distribution of Protocol_type differs significantly in normal and anomalous connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08098a4a-f2dd-423f-bb37-9ec017b876c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:\n",
      "Null Hypothesis (H0): The distribution of Protocol_type is independent of Normal and Anomalous connections.\n",
      "Alternative Hypothesis (Ha): The distribution of Protocol_type is associated with Normal and Anomalous connections.\n",
      "\n",
      "Chi-square Test Results:\n",
      "Chi-square Statistic: 10029.25\n",
      "Degrees of Freedom: 2\n",
      "P-value: 0.0000\n",
      "\n",
      "Conclusion: Reject the null hypothesis. The distribution of Protocol_type differs significantly between Normal and Anomalous connections.\n",
      "\n",
      "Contingency Table:\n",
      "connectiontype  anomalous  normal\n",
      "protocoltype                     \n",
      "0                    6982    1309\n",
      "1                   49089   53600\n",
      "2                    2559   12434\n",
      "\n",
      "Expected Frequencies Table:\n",
      "connectiontype     anomalous        normal\n",
      "protocoltype                              \n",
      "0                3858.773944   4432.226056\n",
      "1               47793.226088  54895.773912\n",
      "2                6977.999968   8015.000032\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table for Protocol_type and Attacks\n",
    "df[\"connectiontype\"] = np.where(df[\"attack\"] == \"normal\", \"normal\", \"anomalous\")\n",
    "contingency_table = pd.crosstab(df[\"protocoltype\"], df[\"connectiontype\"])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print hypotheses and results\n",
    "print(\"Hypothesis:\")\n",
    "print(\"Null Hypothesis (H0): The distribution of Protocol_type is independent of Normal and Anomalous connections.\")\n",
    "print(\"Alternative Hypothesis (Ha): The distribution of Protocol_type is associated with Normal and Anomalous connections.\\n\")\n",
    "\n",
    "print(\"Chi-square Test Results:\")\n",
    "print(f\"Chi-square Statistic: {chi2_stat:.2f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4f}\\n\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Conclusion: Reject the null hypothesis. The distribution of Protocol_type differs significantly between Normal and Anomalous connections.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. No significant association between Protocol_type and Normal/Anomalous connections.\")\n",
    "\n",
    "# Optional: Print the contingency table for reference\n",
    "print(\"\\nContingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "print(\"\\nExpected Frequencies Table:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7806133-c3f4-4d38-bfc6-a2a8acd6c359",
   "metadata": {},
   "source": [
    "# 3. Role of Service in Network Security:\n",
    "\n",
    "Hypothesis: Specific services are targets of network anomalies more often than others.\n",
    "\n",
    "Tests: Chi-square test to compare the frequency of services in normal versus anomaly-flagged connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "115235ba-58fa-4264-aa72-24b1eb1a2c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:\n",
      "Null Hypothesis (H0): The distribution of services is independent of Normal and Anomalous connections.\n",
      "Alternative Hypothesis (Ha): The distribution of services is associated with Normal and Anomalous connections.\n",
      "\n",
      "Chi-square Test Results:\n",
      "Chi-square Statistic: 93240.03\n",
      "Degrees of Freedom: 69\n",
      "P-value: 0.0000\n",
      "\n",
      "Conclusion: Reject the null hypothesis. The distribution of services differs significantly between Normal and Anomalous connections.\n",
      "\n",
      "Contingency Table:\n",
      "Connection_Type  Anomalous  Normal\n",
      "service                           \n",
      "0                        1     186\n",
      "1                        6      67\n",
      "2                      862       0\n",
      "3                        2       0\n",
      "4                      719     236\n",
      "...                    ...     ...\n",
      "65                       3     599\n",
      "66                     780       0\n",
      "67                     689       0\n",
      "68                     617       0\n",
      "69                     693       0\n",
      "\n",
      "[70 rows x 2 columns]\n",
      "\n",
      "Expected Frequencies Table:\n",
      "Connection_Type   Anomalous      Normal\n",
      "service                                \n",
      "0                 87.033015   99.966985\n",
      "1                 33.975455   39.024545\n",
      "2                401.189620  460.810380\n",
      "3                  0.930834    1.069166\n",
      "4                444.473419  510.526581\n",
      "...                     ...         ...\n",
      "65               280.181150  321.818850\n",
      "66               363.025410  416.974590\n",
      "67               320.672446  368.327554\n",
      "68               287.162408  329.837592\n",
      "69               322.534114  370.465886\n",
      "\n",
      "[70 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Categorize connection type as 'Normal' or 'Anomalous'\n",
    "df[\"Connection_Type\"] = np.where(df[\"attack\"] == \"normal\", \"Normal\", \"Anomalous\")\n",
    "\n",
    "# Create a contingency table for Service and Connection_Type\n",
    "contingency_table = pd.crosstab(df[\"service\"], df[\"Connection_Type\"])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print hypotheses and results\n",
    "print(\"Hypothesis:\")\n",
    "print(\"Null Hypothesis (H0): The distribution of services is independent of Normal and Anomalous connections.\")\n",
    "print(\"Alternative Hypothesis (Ha): The distribution of services is associated with Normal and Anomalous connections.\\n\")\n",
    "\n",
    "print(\"Chi-square Test Results:\")\n",
    "print(f\"Chi-square Statistic: {chi2_stat:.2f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4f}\\n\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Conclusion: Reject the null hypothesis. The distribution of services differs significantly between Normal and Anomalous connections.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. No significant association between services and Normal/Anomalous connections.\")\n",
    "\n",
    "# Optional: Print the contingency table and expected frequencies for reference\n",
    "print(\"\\nContingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "print(\"\\nExpected Frequencies Table:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b52d8d-3d3a-4b5f-98f9-b9d9345ab3da",
   "metadata": {},
   "source": [
    "## Feature Engineering Steps\n",
    "Interaction Features: Combine numerical features to create interaction terms.\n",
    "\n",
    "Aggregated Features: Create summary statistics like the mean, sum, or count of certain groups of features.\n",
    "\n",
    "Polynomial Features: Introduce non-linear relationships between features by applying polynomial transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1aaf9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Interaction Features (combining numerical features)\n",
    "df['src_dst_bytes_interaction'] = df['srcbytes'] * df['dstbytes']  # Interaction between source and destination bytes\n",
    "df['num_failed_logins_hot_interaction'] = df['numfailedlogins'] * df['hot']  # Interaction between failed logins and 'hot' indicator\n",
    "df['num_compromised_su_interaction'] = df['numcompromised'] * df['suattempted']  # Interaction between compromised and su attempt\n",
    "\n",
    "# Aggregated Features: Summary statistics over groups of features\n",
    "df['total_data_transfer'] = df['srcbytes'] + df['dstbytes']  # Total data transferred\n",
    "df['total_access_operations'] = df['numfilecreations'] + df['numshells'] + df['numaccessfiles']  # Total access-related operations\n",
    "\n",
    "\n",
    "\n",
    "# Drop any features that you may not need\n",
    "df = df.drop(columns=['srcbytes', 'dstbytes'])  # Dropping original srcbytes and dstbytes if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0858ff2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocoltype</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>land</th>\n",
       "      <th>wrongfragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>numfailedlogins</th>\n",
       "      <th>loggedin</th>\n",
       "      <th>...</th>\n",
       "      <th>dsthostsrvdiffhostrate</th>\n",
       "      <th>attack</th>\n",
       "      <th>lastflag</th>\n",
       "      <th>connectiontype</th>\n",
       "      <th>Connection_Type</th>\n",
       "      <th>src_dst_bytes_interaction</th>\n",
       "      <th>num_failed_logins_hot_interaction</th>\n",
       "      <th>num_compromised_su_interaction</th>\n",
       "      <th>total_data_transfer</th>\n",
       "      <th>total_access_operations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "      <td>anomalous</td>\n",
       "      <td>Anomalous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1891496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>83580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocoltype  service  flag  land  wrongfragment  urgent  hot  \\\n",
       "0         0             1       20     9     0              0       0    0   \n",
       "1         0             2       44     9     0              0       0    0   \n",
       "2         0             1       49     5     0              0       0    0   \n",
       "3         0             1       24     9     0              0       0    0   \n",
       "4         0             1       24     9     0              0       0    0   \n",
       "\n",
       "   numfailedlogins  loggedin  ...  dsthostsrvdiffhostrate   attack  lastflag  \\\n",
       "0                0         0  ...                    0.00   normal        20   \n",
       "1                0         0  ...                    0.00   normal        15   \n",
       "2                0         0  ...                    0.00  neptune        19   \n",
       "3                0         1  ...                    0.04   normal        21   \n",
       "4                0         1  ...                    0.00   normal        21   \n",
       "\n",
       "   connectiontype  Connection_Type  src_dst_bytes_interaction  \\\n",
       "0          normal           Normal                          0   \n",
       "1          normal           Normal                          0   \n",
       "2       anomalous        Anomalous                          0   \n",
       "3          normal           Normal                    1891496   \n",
       "4          normal           Normal                      83580   \n",
       "\n",
       "   num_failed_logins_hot_interaction  num_compromised_su_interaction  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   total_data_transfer  total_access_operations  \n",
       "0                  491                        0  \n",
       "1                  146                        0  \n",
       "2                    0                        0  \n",
       "3                 8385                        0  \n",
       "4                  619                        0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b639be-98a4-4a05-931d-da4fcb01effe",
   "metadata": {},
   "source": [
    "# 4. Connection Status and Anomalies:\n",
    "\n",
    "Hypothesis: Error flags in the Flag feature are significantly associated with anomalies.\n",
    "\n",
    "Tests: Use logistic regression to assess the impact of connection status on the likelihood of an anomaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad4f2708-c2f7-4dcc-9cc7-42bec3a00e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8734917442845047\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     20083\n",
      "           1       0.92      0.80      0.86     17709\n",
      "\n",
      "    accuracy                           0.87     37792\n",
      "   macro avg       0.88      0.87      0.87     37792\n",
      "weighted avg       0.88      0.87      0.87     37792\n",
      "\n",
      "Logistic Regression Coefficients: [[-0.7502049]]\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'attack' column as binary: 'normal' = 0, others = 1\n",
    "df['attack_binary'] = df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Encode the 'flag' column using Label Encoding (or One-Hot Encoding if needed)\n",
    "label_encoder = LabelEncoder()\n",
    "df['flag_encoded'] = label_encoder.fit_transform(df['flag'])\n",
    "\n",
    "# Create the feature matrix (X) and target vector (y)\n",
    "X = df[['flag_encoded']]  # Using only 'flag' feature for now\n",
    "y = df['attack_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Coefficients of the logistic regression model\n",
    "print(f\"Logistic Regression Coefficients: {log_reg_model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe10479-656b-4461-8c91-f77961cd1420",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "\n",
    "If the coefficient is significantly different from 0, it suggests that the flag feature has an impact on predicting network anomalies.\n",
    "\n",
    "## Explanation:\n",
    "\n",
    "Encoding the attack Column:\n",
    "We create a binary attack_binary column where 0 indicates normal connections, and 1 indicates anomalies.\n",
    "\n",
    "Encoding the flag Column:\n",
    "We apply label encoding to convert the categorical values in the flag column into numerical values. Each unique value in flag will be converted to a unique integer. You could also use one-hot encoding if the flag feature has many unique values.\n",
    "\n",
    "Modeling:\n",
    "A logistic regression model is built with flag_encoded as the predictor variable and attack_binary as the target variable. We use train_test_split to split the data into training and testing sets.\n",
    "\n",
    "Evaluation:\n",
    "The model is evaluated using accuracy and a classification report, which includes precision, recall, and F1-score.\n",
    "\n",
    "Coefficients:\n",
    "The coefficients of the logistic regression model indicate the strength and direction of the relationship between the flag feature and the likelihood of an anomaly.\n",
    "\n",
    "The accuracy score indicates how well the model is performing.\n",
    "\n",
    "The classification report shows how the model's predictions compare to the actual values, with precision, recall, and F1-score values for both normal and anomalous connections.\n",
    "\n",
    "The logistic regression coefficient tells you the impact of the flag feature on the probability of anomaly occurrence (higher values indicate a greater likelihood of anomalies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16eab2-f12c-4c39-85ab-7c99e7e67ae9",
   "metadata": {},
   "source": [
    "# 5. Influence of Urgent Packets:\n",
    "Hypothesis: Connections that include urgent packets are more likely to be anomalous.\n",
    "Tests: Logistic regression to evaluate whether the presence of Urgent packets increases the odds of an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb6c6305-4875-4dba-b0bc-6117c015a1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5314087637595258\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69     20083\n",
      "           1       0.00      0.00      0.00     17709\n",
      "\n",
      "    accuracy                           0.53     37792\n",
      "   macro avg       0.27      0.50      0.35     37792\n",
      "weighted avg       0.28      0.53      0.37     37792\n",
      "\n",
      "Logistic Regression Coefficients: [[-1.06406261]]\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'attack' column as binary: 'normal' = 0, others = 1\n",
    "df['attack_binary'] = df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Select the 'urgent' column as the feature and 'attack_binary' as the target\n",
    "X = df[['urgent']]  # Using only 'urgent' feature for now\n",
    "y = df['attack_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Coefficients of the logistic regression model\n",
    "print(f\"Logistic Regression Coefficients: {log_reg_model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f63a9-3209-4481-8666-15ef0101fb8a",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "\n",
    "Accuracy Score: \n",
    "The accuracy score shows how well the model is performing, indicating how well the presence of urgent packets can predict anomalies.\n",
    "\n",
    "Classification Report: \n",
    "This report includes precision, recall, and F1-score for both normal and anomalous connections. It shows the model’s ability to correctly identify anomalies and normal connections.\n",
    "\n",
    "Logistic Regression Coefficients: \n",
    "The coefficient for urgent indicates the relationship between the presence of urgent packets and the likelihood of an anomaly.\n",
    "If the coefficient is positive and significantly different from 0, it suggests that the presence of urgent packets increases the likelihood of an anomaly.\n",
    "A negative coefficient would suggest the opposite (that urgent packets decrease the likelihood of anomalies).\n",
    "\n",
    "## Explanation:\n",
    "\n",
    "Encoding the attack Column: \n",
    "The attack column is encoded as binary: 0 for normal connections and 1 for anomalies (neptune, satan, etc.).\n",
    "\n",
    "Using the urgent Feature: \n",
    "We use the urgent feature, which indicates the presence of urgent packets, as a predictor for the logistic regression model. This feature should already be binary (1 for urgent packets and 0 for non-urgent packets), making it suitable for this analysis.\n",
    "\n",
    "Logistic Regression Model: \n",
    "We use logistic regression with urgent as the independent variable and attack_binary as the dependent variable. The logistic regression model will estimate the odds of an anomaly based on the presence of urgent packets.\n",
    "\n",
    "Model Evaluation: We use accuracy and a classification report to evaluate the model. Additionally, we look at the coefficients of the model to understand the influence of the urgent feature on the likelihood of an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70863ab-28d6-4c7b-ac78-cf8b54a073c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
